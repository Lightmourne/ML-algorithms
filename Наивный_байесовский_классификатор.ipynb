{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lE884Orub03w"
   },
   "source": [
    "# Наивный байесовский классификатор на задаче классификации текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itkISZ5TBKid"
   },
   "source": [
    "## Определение\n",
    "\n",
    "Наи́вный ба́йесовский классифика́тор — простой вероятностный классификатор, основанный на применении теоремы Байеса со строгими (наивными) предположениями о независимости.\n",
    "В зависимости от точной природы вероятностной модели, наивные байесовские классификаторы могут обучаться очень эффективно. Во многих практических приложениях для оценки параметров для наивных байесовых моделей используют метод максимального правдоподобия; другими словами, можно работать с наивной байесовской моделью, не веря в байесовскую вероятность и не используя байесовские методы.\n",
    "\n",
    "Источник: [wikipedia.org](https://ru.wikipedia.org/wiki/%D0%9D%D0%B0%D0%B8%D0%B2%D0%BD%D1%8B%D0%B9_%D0%B1%D0%B0%D0%B9%D0%B5%D1%81%D0%BE%D0%B2%D1%81%D0%BA%D0%B8%D0%B9_%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%82%D0%BE%D1%80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFbrCrpIB3Q9"
   },
   "source": [
    "Перед тем как перейти к применению данного алгоритма на реальных данных, стоит рассмотреть что из себя представляет **теорема Байеса**.\n",
    "\n",
    "Пусть событие $A$ может наступить при условии появления одного из несовместных событий $B_1$, $B_2$, ..., $B_n$, образующих полную группу. Поскольку заранее неизвестно, какое из этих событий наступит, их называют *гипотезами*.\n",
    "\n",
    "*Формула Байеса позволяет переоценить вероятности гипотез после того, как становится известным результат испытания, в итоге которого появилось событие* $A$.\n",
    "\n",
    "<h3 align=\"center\"> $ P(A|B) = \\frac{ P(B|A)P(A) }{ P(B) } $ </h3>\n",
    "\n",
    "$ P(A) $ — априорная вероятность гипотезы $A$\n",
    "\n",
    "$ P(B) $ — вероятность того, что событие $B$ истинно (полная вероятность наступления события $B$)\n",
    "\n",
    "$ P(A|B) $ — вероятность гипотезы $A$ при наступлении события $B$ (апостериорная вероятность)\n",
    "\n",
    "$ P(B|A) $ — вероятность наступления события $B$ при истинности гипотезы $A$\n",
    "\n",
    "*Безусловную вероятность справедливости гипотезы называют априорной (насколько вероятна причина вообще), а условную — с учётом факта произошедшего события — апостериорной (насколько вероятна причина оказалась с учётом данных о событии).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppj8_22JCnIq"
   },
   "source": [
    "> Очень **важное допущение**, без которого использование алгоритма наивного байеса не имело бы смысла, заключается в том, что мы будем считать элементы признака независимыми между собой. Зависимость будет иметь место только между элементом признака (словом) и целевой меткой (классом).\n",
    "\n",
    "В данном случае $A$ - метка класса, $B$ - текст, сотоящий из некоторого набора слов ($B_1$, $B_2$, ..., $B_n$).\n",
    "\n",
    "Нам необходимо найти такой класс $A$, при котором его вероятность для данной строки была бы максимальна.\n",
    "\n",
    "<h3 align=\"center\"> $ A = argmax_A P(A|B) $ </h3>\n",
    "\n",
    "\n",
    "$argmax_x f(x)$ есть значение $x$, при котором $f(x)$ максимальна"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eyn5ZdfQNOBH"
   },
   "source": [
    "Используя теорему Байеса, запишем:\n",
    "\n",
    "$P(A | B_1, ..., B_n) = \\frac{ P(A)P(B_1, ..., B_n | A) }{ P(B_1, ..., B_n) }$\n",
    "\n",
    "На практике интересен лишь числитель этой дроби, так как знаменатель не зависит от $A$ и значения $B_i$ даны, поэтому знаменатель - константа.\n",
    "\n",
    "Числитель эквивалентен совместной вероятности модели:\n",
    "\n",
    "$P(A, B_1, ..., B_n)$, которая может быть переписана следующим образом, используя повторные приложения определений условной вероятности:\n",
    "\n",
    "$P(A, B_1, ..., B_n) =$\n",
    "\n",
    "$ = P(A)P(B_1, ..., B_n | A) =$\n",
    "\n",
    "$ = P(A)P(B_1|A)P(B_2 ..., B_n | A, B_1) =$\n",
    "\n",
    "$ = P(A)P(B_1 | A)P(B_2|A, B_1)P(B_3, ..., B_n | A, B_1, B_2) =$\n",
    "\n",
    "$= P(A)P(B_1 | A) \\cdot ... \\cdot  P(B_n | A, B_1, B_2, ..., B$<sub>n-1</sub>)\n",
    "\n",
    "и т. д. Теперь можно использовать «наивные» предположения условной независимости: предположим, что каждое свойство $B_i$ условно независимо от любого другого свойства $B_j$ при $j ≠ i$.\n",
    "\n",
    "Это означает: $P(B_i | A, B_j) = P(B_i | A)$, таким образом, совместная модель может быть выражена как:\n",
    "$ P(A, B_1, ..., B_n) = P(A)P(B_1 |A) \\cdot ... \\cdot P(B_n|A)$, что эквивалентно следующей записи:\n",
    "<h3 align=\"center\"> $ P(A) = \\prod_{i=1}^{n} P(B_i | A) $ </h3>\n",
    "\n",
    "Это означает, что из предположения о независимости, условное распределение по классовой переменной $A$ может быть выражено так:\n",
    "<h3 align=\"center\"> $P(A | B_1, ..., B_n) = $ </h3>\n",
    "<h3 align=\"center\"> $ = \\frac{1}{Z} P(A)\\prod_{i=1}^{n} P(B_i | A)$ </h3>\n",
    "\n",
    "где $Z = P(B_1, ... , B_n)$ - это масштабный множитель, зависящий только от $B_1, ..., B_n$, то есть константа, если значения переменных известны.\n",
    "\n",
    "\n",
    "> Стоит отметить, что использование для предсказаний произведения вероятностей может привести к численной нестабильности ввиду возможности наличия нулевых вероятностей. Поэтому часто вместо произведения \"чистых\" вероятностей используется сумма их логарифмов, что избавляет от возможности \"зануления\" общей вероятности принадлежности к классу.\n",
    "\n",
    "Источник: [wiki/Наивный байесовский классификатор](https://ru.wikipedia.org/wiki/%D0%9D%D0%B0%D0%B8%D0%B2%D0%BD%D1%8B%D0%B9_%D0%B1%D0%B0%D0%B9%D0%B5%D1%81%D0%BE%D0%B2%D1%81%D0%BA%D0%B8%D0%B9_%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%82%D0%BE%D1%80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYvEoerIWNAW"
   },
   "source": [
    "## Набор данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWN0WmdrWVbi"
   },
   "source": [
    "Для реализации алгоритма и проверки его работы на реальных данных загрузим набор данных IMDB, содержащий 50 тысяч рецензий на фильмы. Набор предназначен для обработки естественного языка или текстовой аналитики.\n",
    "\n",
    "Загрузим набор данных с сайта kaggle по ссылке: [IMDB Dataset of 50K Movie Reviews](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews) (размер архива 27 MB)\n",
    "\n",
    "Набор данных состоит всего из двух колонок:\n",
    "\n",
    "\n",
    "1.   Признак **\"review\"** - содержит текст рецензии на фильм.\n",
    "2.   Целевая метка **\"sentiment\"** - содержит два лейбла (*positive* - позитивная рецензия, и *negative* - негативная рецензия).\n",
    "\n",
    "Необходимо создать модель, которая будет принимать на вход текстовое описание, а на выходе модели мы увидим к какому классу ту или иную рецензию модель отнесет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "O_0ln4ldN-Q8"
   },
   "outputs": [],
   "source": [
    "# Импортиуем необходимые библиотеки для дальнейшей работы\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import string\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "GCTWzCclOUht",
    "outputId": "bd4332ac-4792-4957-abf7-228bdc1d8a05"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загрузим csv-файл в pandas DataFrame\n",
    "# обратите внимание, файл переименован для замены пробела в имени файла,\n",
    "# оригинальное имя: IMDB Dataset.csv\n",
    "df_raw = pd.read_csv('IMDB_Dataset.csv')\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Yr5QNJsTOsEJ"
   },
   "outputs": [],
   "source": [
    "# создаем копию датасета для дальнейших манипуляций над ним\n",
    "# без внесения изменений в исходный\n",
    "df = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WiFXi3i1bEHp"
   },
   "source": [
    "## Предварительная обработка набора данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FMaMkc05Zy7k"
   },
   "source": [
    "Так или иначе все наши признаки в дальнейшем нужно будет закодировать, так как модель будет обрабатывать не исходные категориальные признаки и текстовую последовательность, а числовые признаки.\n",
    "\n",
    "Предлагаю сразу закодировать категориальный признак целевого столбца 'sentiment', где 0 - негативня рецензия, 1 - позитивная рецензия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DPjUT7n9OvcY"
   },
   "outputs": [],
   "source": [
    "# словарь для замены текстовых меток на целочисленные\n",
    "replace_label = {'positive' : 1,\n",
    "                 'negative' : 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "STHjahl4O3xA",
    "outputId": "85037039-1a95-436c-ede4-e5c5f85e27e1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# производим замену целевых меток в датасете на 0 и 1\n",
    "df['sentiment'] = df['sentiment'].map(replace_label)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdPKr6xSQgmA"
   },
   "source": [
    "Для начала необходимо произвести проверку на наличие пропусков или дубликатов.\n",
    "Для наглядности визуализирую все дубликаты, затем мы избавимся от дублирующих строк нашего датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "tL8402JkSIhm",
    "outputId": "54385eb1-8666-449d-ff38-84794d1593fb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34058</th>\n",
       "      <td>\"Go Fish\" garnered Rose Troche rightly or wron...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47467</th>\n",
       "      <td>\"Go Fish\" garnered Rose Troche rightly or wron...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29956</th>\n",
       "      <td>\"Three\" is a seriously dumb shipwreck movie. M...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31488</th>\n",
       "      <td>\"Three\" is a seriously dumb shipwreck movie. M...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47527</th>\n",
       "      <td>\"Witchery\" might just be the most incoherent a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47876</th>\n",
       "      <td>this movie sucks. did anyone notice that the e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44122</th>\n",
       "      <td>well, the writing was very sloppy, the directi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23056</th>\n",
       "      <td>well, the writing was very sloppy, the directi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10163</th>\n",
       "      <td>when I first heard about this movie, I noticed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15305</th>\n",
       "      <td>when I first heard about this movie, I noticed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>824 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "34058  \"Go Fish\" garnered Rose Troche rightly or wron...          0\n",
       "47467  \"Go Fish\" garnered Rose Troche rightly or wron...          0\n",
       "29956  \"Three\" is a seriously dumb shipwreck movie. M...          0\n",
       "31488  \"Three\" is a seriously dumb shipwreck movie. M...          0\n",
       "47527  \"Witchery\" might just be the most incoherent a...          0\n",
       "...                                                  ...        ...\n",
       "47876  this movie sucks. did anyone notice that the e...          0\n",
       "44122  well, the writing was very sloppy, the directi...          0\n",
       "23056  well, the writing was very sloppy, the directi...          0\n",
       "10163  when I first heard about this movie, I noticed...          1\n",
       "15305  when I first heard about this movie, I noticed...          1\n",
       "\n",
       "[824 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated(keep=False)].sort_values(by=['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XUvcYTTCQoFg",
    "outputId": "bb236ccc-6b60-461d-be93-48af4af40266"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Удалено дубликатов: 418\n",
      "--------------------\n",
      "Null:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "review       False\n",
       "sentiment    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shape = df.shape[0]\n",
    "df = df.drop_duplicates(ignore_index=True)\n",
    "print(f'Удалено дубликатов: {df_shape - df.shape[0]}')\n",
    "print('-----'*4)\n",
    "print('Null:')\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EqD9_hD_byqG",
    "outputId": "6d0c51c1-7389-4486-b0d2-c640b26036ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим одну из рецензий, мы увидим что текст содержит в себе HTML-теги,\n",
    "# а также знаки пунктуации, кроме того в тексте присутствуют буквы в верхнем\n",
    "# регистре\n",
    "# Cлово \"The\" и \"the\" в данном случае будут считаться двумя разными словами,\n",
    "# для того чтобы этого избежать нужно привести весь текст к нижнему регистру\n",
    "print(df_raw.review[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVP9U5rIbd4T"
   },
   "source": [
    "Кроме того, текст может быть \"загрязнен\" веб-ссылками, e-mail-адресами, специальными знаками.\n",
    "\n",
    "Для более лучшей работы модели необходимо стандартизировать входные последовательности. Для этого напишем функцию ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "oZ44mPoWO_Wf"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Функция, которая принимает на вход строку и производит\n",
    "    чистку от специальных символов, знаков пунктуации, ссылок,\n",
    "    адресов электронных почт, цифр, HTML-тегов, приводит все\n",
    "    слова к нижнему регистру, а также удаляет пробелы в начале\n",
    "    и конце всей строки, и в тех местах, где они могли образоваться\n",
    "    в результате чистки внутри текста\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    clean_text = soup.get_text()\n",
    "    clean_text = re.sub(r'\\s+', ' ', clean_text)\n",
    "    clean_text = re.sub(r'http\\S+|www\\S+|ftp\\S+', '', clean_text)  # Удаление ссылок\n",
    "    clean_text = re.sub(r'[\\w\\.-]+@[\\w\\.-]+', '', clean_text)  # Удаление email\n",
    "    clean_text = re.sub(r'\\d+', '', clean_text)  # Удаление цифр\n",
    "    clean_text = re.sub(f\"[{string.punctuation}]|(?<!\\w)-|-(?!\\w)\", \"\", clean_text)\n",
    "    clean_text = clean_text.lower()  # Приведение к нижнему регистру\n",
    "    clean_text = re.sub(r'\\s+', ' ', clean_text.strip())  # Удаление лишних пробелов\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "oQTwsLTWTZzp"
   },
   "outputs": [],
   "source": [
    "# Применяем функцию к столбцу, который необходимо \"почистить\"\n",
    "df['review'] = df['review'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uznrq4QNTzhD"
   },
   "source": [
    "Для сравнения визуализируем как текст выглядел до предварительной обработки и как эта же строка выглядела после применения к ней функции clean_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LCIBLu1rTxep",
    "outputId": "cbf1c540-5b0c-4b5e-f18b-92cf4a83ff9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.\n",
      "\n",
      "a wonderful little production the filming technique is very unassuming very oldtimebbc fashion and gives a comforting and sometimes discomforting sense of realism to the entire piece the actors are extremely well chosen michael sheen not only has got all the polari but he has all the voices down pat too you can truly see the seamless editing guided by the references to williams diary entries not only is it well worth the watching but it is a terrificly written and performed piece a masterful production about one of the great masters of comedy and his life the realism really comes home with the little things the fantasy of the guard which rather than use the traditional dream techniques remains solid then disappears it plays on our knowledge and our senses particularly with the scenes concerning orton and halliwell and the sets particularly of their flat with halliwells murals decorating every surface are terribly well done\n"
     ]
    }
   ],
   "source": [
    "print(df_raw.review[1])\n",
    "print()\n",
    "print(df.review[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cc_io83pUkjU"
   },
   "source": [
    "Отлично, наша функция работает, можно приступать к дальнейшим действиям."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QkEqSaImUv3P"
   },
   "source": [
    "Сам набор данных сбалансирован по классам, в других случаях потребуется применение дополнительных техник для того чтобы решить проблему дисбаланса классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "JvAFGYUUUFVw",
    "outputId": "15aa329e-219c-40c6-bf87-451bd5751ca6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           review\n",
       "sentiment        \n",
       "0           24698\n",
       "1           24884"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверка баланса классов в столбце с целевыми метками\n",
    "df.groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fY15UUDlVG2z"
   },
   "source": [
    "Для того чтобы наш классификационный алгоритм смог работать с текстовыми данными нам нужно выполнить кодирование признака \"review\". Так как это демонстрационная рабочая тетрадь, то кодировать будем \"вручную\", создавая словарь, который будет содержать в качестве ключа - каждое уникальное слово из всего текстового корпуса (все объекты (рецензии) признака (столбца) \"review\"), а в качестве уникальный индекс для этого слова.\n",
    "\n",
    "Так делать **не нужно**, в рамках ml-библиотек реализованы:\n",
    "\n",
    "\n",
    "*   OneHotEncoder\n",
    "*   CountVectorizer\n",
    "*   TfidfVectorizer\n",
    "\n",
    "Вариант ниже *демонстрационный*, написан для понимания как в дальнейшем работает наш алгоритм наивного байеса.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1QWQhqsUVCMi"
   },
   "outputs": [],
   "source": [
    "# функция для создания и наполнения словаря уникальными словами\n",
    "def encode_reviews(df, feature):\n",
    "    index = 0\n",
    "    dictionary = {}\n",
    "    # перебираем все элементы (тексты) признака (в нашем случае это\n",
    "    # будет \"review\")\n",
    "    for i in range(df[feature].shape[0]):\n",
    "        # итерируемся по каждому слову в конкретном тексте\n",
    "        for word in df[feature][i].split():\n",
    "            # если слова нет в словаре - добавляем его и присваиваем индекс\n",
    "            if word not in dictionary:\n",
    "                dictionary[word] = index + 1\n",
    "                index += 1\n",
    "            else:\n",
    "                pass\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "spuQN98PXGOl"
   },
   "outputs": [],
   "source": [
    "# кодируем слова\n",
    "encode_dict = encode_reviews(df, 'review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pxBi27TVYPeT",
    "outputId": "64403d8b-63c9-41bc-df87-c8756bf95434"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уникальных слов в словаре: 215507\n",
      "Первые десять слов:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('one', 1),\n",
       " ('of', 2),\n",
       " ('the', 3),\n",
       " ('other', 4),\n",
       " ('reviewers', 5),\n",
       " ('has', 6),\n",
       " ('mentioned', 7),\n",
       " ('that', 8),\n",
       " ('after', 9),\n",
       " ('watching', 10)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Уникальных слов в словаре: {len(list(encode_dict.keys()))}')\n",
    "# посмотрим на первые десять уникальных слов в словаре\n",
    "print('Первые десять слов:')\n",
    "list(encode_dict.items())[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YheqcXvtdgBV"
   },
   "source": [
    "Теперь нам необходимо произвести кодировку всех слов в датафрейме, для этого напишем функцию замены слов в каждой рецензии на значение ключа из нашего словаря выше.\n",
    "\n",
    "Напомню ключем является само слово, значением этого ключа является уникальное число. На эти числа мы и будем производить замену всех слов во всем корпусе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Qx6NmrxFyAar"
   },
   "outputs": [],
   "source": [
    "# Функция для замены слов в тексте\n",
    "def replace_words_with_dict_values(text, dictionary):\n",
    "    words = text.split()\n",
    "    replaced_words = [dictionary.get(word) for word in words]\n",
    "    return replaced_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1ChS0RXpVEv",
    "outputId": "30d77eaa-b85d-4850-b5fa-693647b77fa8"
   },
   "outputs": [],
   "source": [
    "# Кодируем\n",
    "# Примените функцию к колонке 'review'\n",
    "df['review'] = df['review'].apply(lambda x: replace_words_with_dict_values(x, encode_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zr70B6atydqR"
   },
   "source": [
    "Выведем на экран датасет, чтобы убедиться что замена произведена"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "zgyNLDz_rtvF",
    "outputId": "7e04423a-1082-4012-b4b7-b0c6fb549145"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[48, 190, 191, 192, 3, 193, 194, 22, 195, 196,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[137, 270, 21, 33, 48, 190, 271, 59, 272, 273,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[347, 348, 48, 349, 84, 48, 191, 350, 351, 352...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[394, 395, 396, 42, 3, 273, 2, 397, 22, 48, 39...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...          1\n",
       "1  [48, 190, 191, 192, 3, 193, 194, 22, 195, 196,...          1\n",
       "2  [137, 270, 21, 33, 48, 190, 271, 59, 272, 273,...          1\n",
       "3  [347, 348, 48, 349, 84, 48, 191, 350, 351, 352...          0\n",
       "4  [394, 395, 396, 42, 3, 273, 2, 397, 22, 48, 39...          1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWFZ-0HQeS-f"
   },
   "source": [
    "Теперь наш набор данных выглядит таким образом:\n",
    "\n",
    "\"review\" - массив из чисел, вместо строки из слов,\n",
    "\"sentiment\" - метка (0 или 1)\n",
    "\n",
    "Визуализируем любую точку данных в датафрейме:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WdmnUjB6eFOV",
    "outputId": "1d5835f9-1dd7-4870-899f-490484f26618"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       [21, 22, 1, 2, 3, 1961, 742, 137, 87, 138, 547...\n",
       "sentiment                                                    1\n",
       "Name: 115, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[115]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NmJ5g3Nyo81"
   },
   "source": [
    "На данном этапе подготовка данных завершена, приступаем к реализации алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jiX02ekgfCXr"
   },
   "source": [
    "## Реализация алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "LNZMkT1Awowq"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from math import log\n",
    "\n",
    "# функция для обучения модели\n",
    "def train(train_data):\n",
    "    # создаем два словаря, labels будет содержать в качестве ключа - номер класса (0 или 1),\n",
    "    # а в качестве значения будет содержать общее количество объектов этого класса\n",
    "    # словарь frequency будет содержать в качестве ключа (номер класса, слово),\n",
    "    # а в качестве значения количество использования этого слова во всех текстах для каждого\n",
    "    # из классов\n",
    "    labels, frequency = defaultdict(lambda:0), defaultdict(lambda:0)\n",
    "    for sequence, label in train_data:\n",
    "        # находим лэйбл класса и считаем насколько часто он встречается\n",
    "        labels[label] += 1\n",
    "        # sequence - это текст в каждой точке данных (закодированный)\n",
    "        for word in sequence:\n",
    "            # проходимся по всем словам и считаем их частоты (кол-во элементов)\n",
    "            # пример frequency (1, 25311): 32 ). где 1 - класс, 25311 - порядковый\n",
    "            # индекс уникального слова, 32 - количество раз использования этого слова\n",
    "            # во всех текстах для класса №1\n",
    "            frequency[label, word] += 1\n",
    "    # нормализуем частоты слов и классов\n",
    "    # распаковываем лейбл и слово из частот, делим на кол-во элементов этого класса\n",
    "    for label, word in frequency:\n",
    "        frequency[label, word] /= labels[label] # для получения частоты нормируем на кол-во элементов в классе\n",
    "\n",
    "    # кол-во элементов для каждого класса делим на кол-во семплов\n",
    "    for c in labels:\n",
    "        labels[c] /= len(train_data)\n",
    "\n",
    "    # мы получили labels - соответсвует априорной вероятности P(A)\n",
    "    # и frequency - frequency P(B|A) - вероятность натупления события B (B - истина),\n",
    "    # если A - истина, т.е. вероятность принадлежности слова к конкретному классу\n",
    "    return labels, frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfD95Jj5tKSK"
   },
   "source": [
    "Как и было сказано в определении вместо произведения \"чистых\" вероятностей используется сумма их логарифмов, что избавляет от возможности \"зануления\" общей вероятности принадлежности к классу. Дополнительный коэффициент необходим из-за того что значения вероятностей сами по себе очень маленькие, поэтому домножаем на константу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "bvQ4ytO0owC0"
   },
   "outputs": [],
   "source": [
    "def predictor(classifier, words):\n",
    "    labels, prob = classifier\n",
    "    return min(labels.keys(),\n",
    "        key = lambda cl: -log(labels[cl]) + sum(-log(prob.get((cl,feat), 10**(-7))) for feat in words) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABdWhVPKnKhI"
   },
   "source": [
    "Разбиваем датафрейм на обучающую и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "p4KpwbYij1Sn"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'],\n",
    "                                                    test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "_vbmOb0gjvSV"
   },
   "outputs": [],
   "source": [
    "features = [(X_train.iloc[i], y_train.iloc[i]) for i in range(len(X_train))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H8eOkPodnSzb"
   },
   "source": [
    "Обучаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "5T88pUQ3kmNO"
   },
   "outputs": [],
   "source": [
    "classifier = train(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JfkoGhpurlS"
   },
   "source": [
    "Визуализируем истинный ответ и предсказание модели у для одинакового текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FwaHzmn1mcX9",
    "outputId": "67651afd-cfbf-44d7-d9ed-2f99a61cdd37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true label 0\n"
     ]
    }
   ],
   "source": [
    "print('true label', y_test.iloc[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fSw3X4u1mgUp",
    "outputId": "00fef066-d849-48bb-b5b7-e0d4d28103d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted 0\n"
     ]
    }
   ],
   "source": [
    "print('predicted', predictor(classifier, (X_test.iloc[200])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77s9fmP_07oc"
   },
   "source": [
    "Для того чтобы прочитать текст рецензии, нам нужно декодировать наш массив из чисел в слова, для этого напишем функцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "FrCmZTF4vc5u"
   },
   "outputs": [],
   "source": [
    "def decode_values(array):\n",
    "    inverse_dict = {v: k for k, v in encode_dict.items()}\n",
    "    output = ''\n",
    "    for num in array:\n",
    "        output += str(inverse_dict[num]) + ' '\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xap914rs1J5e"
   },
   "source": [
    "Визуализируем. Как мы видим, человеку фильм не понравился."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "3fpnuj29x-Ti",
    "outputId": "7567ea19-de15-44dd-e89f-32c6a953da7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the long list of big names in this flick including the ubiquitous john mills didnt bowl me over to the extent that i couldnt judge the film on its actual merits it is full of stereotypes caricatures and standard set scenes from the humble airace hero to the loudmouthed yank flyer the music track was such that at one point about an hour before the end i thought the film was over loud rising crescendo grand flourish and finish then silence but then the movie continued i found no real storyline haphazard writing but smartlypressed uniforms and the pretty jean simmons prenose job with a rousing little ditty i cannot say that this picture has any of the ingredients which make a film great i found it maudlin mawkish and minor '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_values(X_test.iloc[200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAKbPxLSnXjh"
   },
   "source": [
    "## Оценка по метрике f1-score macro avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfYlne5M1d2T"
   },
   "source": [
    "И в завершении для оценки работы модели в целом, а не на выборочных примерах импортируем classification_report() из библиотеки sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "eTzWd3ZDmhvg"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predicted = [predictor(classifier, (X_test.iloc[i])) for i in range(len(X_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aufDh9wom9n5",
    "outputId": "9fefb751-ee4e-4c90-932f-4149fa901d16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      7404\n",
      "           1       0.83      0.83      0.83      7471\n",
      "\n",
      "    accuracy                           0.83     14875\n",
      "   macro avg       0.83      0.83      0.83     14875\n",
      "weighted avg       0.83      0.83      0.83     14875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7niw-dF11rs5"
   },
   "source": [
    "## Заключение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2A8ZMkk1u49"
   },
   "source": [
    "В этой рабочей тетради мы посмотрели что из себя представляет алгоритм наивного байеса на основе теоремы Байеса с некоторыми строгими допущениями о независимости. Получили некоторое представление о том как можно предобработать текстовые данные перед подачей их на вход модели для дальнейшей её обучения на них. Обучили модель и провели проверку полученных предсказаний модели.\n",
    "\n",
    "Рузультат 0.83 по метрике f1-score macro avg - это неплохой бейзлайн для этой задачи, учитывая скорость работы данного алгоритма. Данный алгоритм можно использовать не только в задачах бинарной классификации, но и в задачах с многоклассовой классификацией.\n",
    "\n",
    "В данной рабочей тетради не было цели показать дополнительные приемы для улучшения работы алгоритма. Вы можете ознакомиться с модификациями и реализациями алгоритма нивного байеса (ComplementNB, MultinomialNB, BernoulliNB, CategoricalNB, GaussianNB) в библиотеке [sklearn](https://scikit-learn.org/stable/modules/naive_bayes.html)\n",
    "\n",
    "Рекомендуется ознакомиться с:\n",
    "\n",
    "\n",
    "*   [sklearn.feature_extraction.text.CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n",
    "*   [sklearn.feature_extraction.text.TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
    "*   список [\"stopwords\" библиотеки nltk](https://www.nltk.org/search.html?q=stopwords)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
